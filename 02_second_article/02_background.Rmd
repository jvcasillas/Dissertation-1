# 1. Introduction
Learning a second language as adults is difficult.
We draw from our previous knowledge to make up for the shortcomings we have in our second language (L2).
The type of previous knowledge we resort to is varied, from other languages we speak to our musical training to learn L2 tones.
If, how, and to what extent skills are transferred in learning is a hot debate.
Transfer could take place between domain-general and domain-specific mechanisms and between domain-specific mechanisms alone.
Transfer of domain-specific mechanisms alone in regards to language has been widely tested with music, for example, in learning of tones in a second language [@tang2016musical] or speech processing [e.g., @dittinger2016professional; @fitzroy2013musical; @musacchia2007musicians].
In speech processing, anticipation of information plays an important role to ease comprehension and processing load.
Inability to predict oncoming information and cognitive overload may be a source of lack of comprehension in second language learners.
While speech prediction improves with language exposure [e.g., _@Primerexperimento_, @sagarra2018suprasegmental], the issue still remains how speech processing is affected by other cognitive capacities.

In this paper, we investigate how auditory abilities condition speech prediction in a first language (L1) and in an L2.
Specifically, we aimed to investigate how pitch and rhythm innate abilities condition prediction of verb tense suffixes in L1 and L2 speakers of Spanish when cued by lexically stressed and unstressed syllables.
To observe the interaction between innate auditory abilities with the L1 in acquiring and developing L2 processing skills, we tested speakers whose L1s have lexical stress but in which pitch is not preeminent as an acoustic correlate (English and Spanish) with speakers whose L1 does not have lexical stress but for whom pitch is important (Mandarin Chinese). 
In addition Spanish and Mandarin Chinese are similar in terms of rhythms as they are syllable-timed, while English is stress-timed.

# 2. Background
## 2.1. Music and speech
Research with musicians has been prolific in providing evidence in support of the link between speech and music.
Behavioral online studies and neurocognitive studies have revealed that musical abilities influence positively the production and perception of linguistic sound structures in adults [@wong2007musical] and L2 learners [@marques2007musicians; @slevc2006individual].
Similarly, neurocognitive studies reveal that musicians process speech in a more enhanced way and more synchronously to its onset than non-musicians [e.g., @dittinger2016professional; @fitzroy2013musical; @musacchia2007musicians]. 
In a meta-analysis, @kraus2010music concluded that music training can cause functional and structural changes in the brain.
These changes may translate into improvement in language performance as music shares with language physiological resources that process auditory information.
Given that music and language share physiological resources and that musical practice gives an advantage in speech processing and in L2 acquisition, the relationship between both domains may extend further than training.
In other words, varying innate abilities may be responsible for individual variation of L2 processing, in particular of phonology, among learners of L2s.
Since music is a broad term, here we will focus on pitch, rhythm and their relationship with speech processing in an L1 and an L2.

_Pitch_   
Pitch is the frequency associated to a sound wave; this frequency places the sound within a scale ranging from low to high in perception [@klapuri2006introduction]. 
Pitch in music plays a similar role to the one it plays in language. 
In language, a listener must process the melodic contour of speech, that is, the changes up and down of pitch in order to understand the meaning conveyed by prosody [@dilley2005phonetics].  
For example, a rising pitch contour signals a question (“Coffee?”), while a falling intonation signals a statement (“Coffee.”). 
Apart from the phrasal and sentential intonation, pitch also affects tones and predominance of a syllable against others within a word. 
In music, pitch affects the note we hear.    

Pitch is not only a common acoustic correlate in speech and music.
Knowledge and perception abilities of pitch in one of the two auditory domains translates in many cases into increased perception abilities in the other domain [@bidelman2013tone; @chan2019lexical], such that native speakers of tonal languages discriminate absolute pitch in music more easily [e.g., @chua2014effect; @deutsch2009absolute; @ngo2016effects; @tsukada2015perception].
Native tonal speakers, in fact, perform more similarly to musicians than to non-tonal non-musicians in most pitch and music perception tasks [@bidelman2013tone].
One exception to this association appears to be relative pitch, whose discrimination is not facilitated when through L1 tone knowledge [@ngo2016effects]. 
In turn, musicianship contributes to better lexical tone perception even in a tonal language [@tang2016musical].
Because of these results, some authors have suggested that music and language abilities transfer bidirectionally [@bidelman2013tone].

The transfer may also happen when an L2 is involved, although the effects may be weaker.
Tonal memory is significantly correlated to the skill to discriminate L2 vowels [@mokari2018perceptual], and musical knowledge contributes to L2 tone discrimination [@ngo2016effects].
However, musical knowledge does not contribute to the creation of L2 tone-segment connections when the L1 does not encode tones; only a tonal L1 promotes the creation of L2 tone-segment connections and of a rule-like system of L2 tone information [@chan2019lexical]. 
Likewise, musical ability in general is not associated with the ability to discriminate and produce L2 sounds [@mokari2018perceptual].

From this set of results, we can deduce that there is a limit in the reciprocal influence between music and language (musical and linguistic pitch for the purpose of this project), but where this limit lies has not been ascertained. 
The research on the relationship of speech sounds with music has been mostly conducted with tones and about discrimination.
Exploring other structures in speech that conform the prosody of a language, namely lexical stress and moras, could provide insight into the connection between pitch and speech.

_Rhythm_    
Rhythm is defined as a pattern of recurrent time intervals that usually occur periodically [@berlyne1971aesthetics].
This periodic nature allows to predict the start of an interval or the next recurring event based on what has already been perceived [@fraisse2013rhythm; @martin1972rhythmic]. 
A typical response to a rhythm is synchronized movement to it. 
This sensorimotor behavior is based on anticipation of when the next beat is coming, especially at slow tempi [@nozaradan2016individual; @van2015sensorimotor].
Ability to perform this anticipation grows in accuracy with years of musical training [@nozaradan2016individual]. 
Prediction of oncoming beats is also present in rhythms with tempo changes [@van2015sensorimotor].   

Within the auditory modality, music is probably the most obvious instance of rhythm, but other domains such as language also follow rhythmic patterns.
Metrical expectancies are automatically generated as we listen to speech [e.g., @magne2016speech; @rothermich2012rhythm; @schmidt2009event]. 
Speakers use stress patterns to generate the expectancies. 
The expectancies are created because the stress patterns are connected to other linguistic levels. 
For instance, stress can be associated with word endings [@soto2001], such that by hearing a specific stress patterns, the speaker can predict verb tense [@sagarra2018; @primerexperimento].
Speakers need to learn these associations.
External factors such as learning context [@primerexperimento] or verb frequency may contribute to the easiness with which the connections is created. 
However, internal factors may also contribute. 

Individual differences in music rhythm abilities can account for speech rhythm sensitivity [@magne2016].
The similarity of rhythmic processing in music and speech may involve shared cognitive mechanisms to perceive and process the rhythms in different domains that may be causing the individual differences.
If the mechanisms are shared, then increased abilities in rhythm, be them innate or acquired through practice, may have an effect on discrimination and processing of rhythms in language.
Indeed, rhythmic abilities and perception condition L1 and L2 processing. 
Matching metrical primes facilitate processing of sentences in the L1 [@cason2015bridging].
ERP recordings have shown that on-beat sequence primes result in faster L1 speech processing than off-beat primes in adults [@cason2012rhythmic]. Rhythmic production is positively associated with L2 lexical stress placement and rhythm perception with the L2 learning experience [@bhatara2015foreign; @cason2019rhythmic].
Better increased rhythmic perception, in contrast, is not associated with adults' reading abilities in an L1 or L2 [@swaminathan2018explaining].
Swaminathan and colleagues were, nevertheless, mixing modalities (written text and heard rhythms), while Cason and colleagues were not. 
We could therefore hypothesize that a relationship between speech and rhythm is still not precluded.
This conclusion would also agree with with association learning models proposing that the more similar two cognitive specific domains are, the likelier the transfer of abilities and mechanisms between them is.

In order to extend the current findings on the association between music and speech to lexical stress and predictive processing, we tested pitch, rhythm and speech anticipation abilities of monolingual and L2 speakers of Spanish.
There is evidence for the existence of prediction processes in music [e.g., @salimpoor2015predictions] as well as in language.
Anticipation in music can be cued through syntactic structure [@sammler2013syntax] or acoustic properties [@loui2007harmonic].
In language, there are many layers of prediction.
Importantly for this study, phonology can cue outcomes.

## 2.2. Linguistic anticipation
Anticipation alleviates the load of constantly processing the information that we receive from the world. 
At a large scale, we anticipate what is going to happen in movies and books. 
At smaller scales, we anticipate movements in sports, other drivers' actions, and we also anticipate what we read and what we hear. 
In linguistic anticipation, we use cues of different kinds to predict oncoming linguistic information. 
Predictive processing in language is especially efficient in the L1, and mediated by factors like L1 transfer, L2 proficiency, or working memory in the L2. 
These factors may interact with each other to generate successful or unsuccessful predictions.

Relevant for this study, predictions may be driven by phonological information.
Depending on the language, coarticulation [@salverda2014immediate], intonation [@nakamura2012immediate; @weber2006role], lexical stress [@correia2013word; @sagarra2018suprasegmental], pauses between clauses [@hawthorne2014pauses; @kjelgaard1999prosodic], vowel duration [@rehrig2017acoustic], and tone [@roll2015neurolinguistic; @roll2011activating] can bue cues to outcomes.




Linguistic prediction allows listeners to anticipate upcoming words and regions [@brennan2019hierarchical; @yang2019clause], and word endings [@roll2010word; @sagarra2018suprasegmental; @soto2001segmental]. Here, I will focus briefly on suffix prediction. Predictions of morphosyntactic elements can be generated through determiners [in Dutch, @huettig2016prediction; in Spanish, @dussias2013gender; @lew2010real; in German, @hopp2013grammatical; in French, @dahan2000linguistic]. Determiners can provide information about number [@marull2017second], gender [@dahan2000linguistic], and case [German @hopp2015semantics; Japanese, @mitsugi2016use].     
Within the very word containing the suffix to be predicted, phonological information such as tone or lexical stress can cue the generation of the correct anticipation of word endings. Swedish speakers use tonal cues to predict noun number [if low tone, then singular, _fisken_ 'fish~[SG]~'; if high tone, then plural, _fiskar_ 'fish~[PL]~,' @roll2010word; @soderstrom2015using; @roll2013word] and verb tense [if low tone, then present, _skrämmer_ 'I scare'; if high tone, then past, _skrämde_ 'I scared,' @soderstrom2012processing; @roll2015neurolinguistic]. Similarly, Spanish speakers use lexical stress to predict verbal tense [if first syllable stressed, then present; if unstressed, then past: _CANta_ 'he sings' vs. _canTÓ_ 'he sang,' @sagarra2018suprasegmental] and noun ending [ _PRINcipe_ 'prince' vs. _prinCIPIO_ 'beginning,' @soto2001segmental]. Finally, English natives use vowel duration to predict voice [if shorter vowel duration, then active: 'the girl was pushing the boy'; if longer vowel duration, then passive: 'the girl was pushed by the boy,' @rehrig2017acoustic].    
Although findings on anticipation in L1 show that typical L1 speakers tend to perform predictive language processing, it is unclear how individual variability in cognitive capacities, i.e. working memory, can affect the efficacy of the predictions. @huettig2016prediction found through eye-tracking that the variance between participants in fixating on the correct target noun based on gendered article in Dutch could be accounted for working memory. However, @sagarra2018suprasegmental found also by means of eye-tracking that working memory played no role, or a marginal one, in L1 Spanish speakers’ capacity to anticipate verbal tense based on lexical stress. Similarly, @otten2009does found no effect of working memory on L1 anticipation in an ERP study. It is difficult to interpret these results, as whereas the technique was the same in the eye-tracking studies, the domains under research cannot explain the differences. @sagarra2018suprasegmental found none focusing on the role of prosodic cues, and @huettig2016prediction found a working memory effect focusing on the role of morphosyntactic information, but @otten2009does found no effect either also focusing on the role of morphosyntactic information but using a different online method. It is possible that different levels of linguistic complexity interact with behavioral or brain activity performance, and only in certain cases the impact of differences in working memory capacities are visible in linguistic anticipation. However, the scant amount of research on the interaction between linguistic anticipation and working memory capacities forces to make interpretations of the findings so far with caution.

#### 2.1.2.2. L2 speakers
Anticipation in L2 speakers is controversial because different studies revealed different findings. Particularly in morphosyntactic anticipation, some studies find that L2 speakers can generate predictions [@dussias2013gender], while others have found they cannot [@hopp2016learning], or only in certain situations [@lew2010real] or specific levels of proficiency [@sagarra2018suprasegmental]. Two of the factors that could account for the variability in L2 anticipation performance and that often appear together are proficiency and cross-linguistic differences. Another factor that could explain the ability to predict in an L2 or not is whether morphosyntax is the cue, the outcome, or both.
It is difficult to disentangle the influence of L1 transfer and L2 proficiency because they are often confounded variables in studies lacking language pairs with different L1s. Furthermore, the combination of L1 transfer and L2 proficiency can happen at different levels of linguistic processing, from the smaller parts like morphology to higher-order levels. At higher-order levels research is very scant. @gruter2013l2, @gruter2014role and @gruter2016l2 explored whether L1 speakers of Korean or Japanese could anticipate the correct oncoming syntactic structure in the discourse in L2 English based on coreference. While L2 speakers were sensitive to the cue, they did not use it to anticipate the structure of the syntactic event. At lower levels where phonology and morphosyntax are involved, there is some more research.   
Aticipation of and based on morphosyntax in an L2 has been tested primarily with gender [e.g., @hopp2013grammatical]. As opposed to L1 anticipation, however, morphosyntactic anticipation in the L2 is determined by the listener's proficiency in the L2 [@sagarra2018suprasegmental] and their L1. The L1 linguistic system can both help [@dussias2013gender] and hinder [@dupoux2008persistent] L2 processing. 
In L2 morphosyntactic anticipation, the gender in the determiner is a reliable cue to gender suffixes in nouns, although some restrictions apply. In L2 German, determiner gender is reliable if the L2 speaker uses the gender system target-like [@hopp2013grammatical; @hopp2016learning]. In L2 Spanish, predictions may be generated if the L1 also has a gender system [@dussias2013gender], or in case the L1 lacks a gender system, if the predictions are to be made on novel nouns [@gruter2013l2], or if the nouns are highly frequent [@lew2010real]. Other morphosyntactic elements such as number are not as reliable as cues [@marull2017second], and for others, like case, the cue-outcome connection is directly not created [@hopp2015semantics; @mitsugi2016use].     
In morphosyntactic anticipation other factors might be at play, like L1 transfer and L2 proficiency. The workings of these factors start at lower levels of proficiency. @dussias2013gender examined L1 Italian and L1 English learners of L2 Spanish’s ability to use gender agreement as an anticipation cue. L1 Italian speakers could make use of the gender cue partially to make agreement anticipations at lower levels of proficiency, whereas L1 English speakers could not. L1 English speakers can only start to use gender as a cue at high-intermediate levels, under frequency or novelty conditions of the noun [@gruter2013l2; @lew2010real, respectively]. Italian speakers were presumably transferring their gender agreement knowledge from the L1 to the L2 in order to make the correct predictions. English speakers, however, lack this knowledge in their L1 so no extrapolation was possible. Additionally, it has been argued that lacking the representation of gender marking in the L1 might not only prevent prediction in an L2 based on that cue, but also hinder it [@hopp2016learning]. This proposal fits with @lew2010real findings that L1 English speakers at an intermediate level of proficiency cannot use gender marking to anticipate oncoming nouns in L2 Spanish, but they can use definiteness in articles to anticipate known nouns.     
While gender has been the cue more widely researched, but shared forms, number and case have also been included in past investigations. Having a similar system in terms of form can be helpful. @liburd2014investigating examined the abilities of beginning learners of L2 Dutch with English as L1 to use determiners with similar, different, and unique forms in English and Dutch to anticipate nouns. The eye-tracking data collected suggest that the English speakers were faster and more accurate in generating their predictions when the form was similar in their L1 and L2. Apart from gender, the influence of L2 proficiency is also visible in other cues such as number. Intermediate English speakers of L2 Spanish cannot use number to anticipate numbers suffix in a noun but advanced speakers can [@marull2017second]. In the case of case, the difficulty is never overcome, regardless of the L2 speaker's proficiency [@hopp2015semantics]. In Hopp's study, the L1 of the speakers was English. Like with gender, lacking a case system representation in the L1 might be preventing, and even hindering, the creation of case cue-suffix outcome connection.      
The conclusion that lack of L1 representation prevents L2 anticipation might only be applicable to morphosyntactic cases, or cases of lower proficiency, as it does not account for anticipatory behavior regarding phonology. @rehrig2017acoustic investigated whether L2 speakers could use suprasegmental information in a word stem like vowel lengthening to predict its suffix when their L1 lacked representation for those phenomena. They found that proficient L2 speakers did use the suprasegmental information, but learners at lower proficiencies did not. Similar studies focusing on tone have yielded similar results [e.g. @schremm2016implicit; @berthelsen2018neural].       
When the acoustic correlate does have a representation in the L1 but it differs from the one typical in the L2, results become messier. On the one hand, @sagarra2018suprasegmental found that L1 English speakers with advanced L2 Spanish could use lexical stress as a cue to anticipate verbal endings when the stress appeared in CVC syllables but not in CV syllables, and L2 Spanish beginners could not use stress to anticipate verb suffixes in either case. On the other hand, @dupoux2008persistent found that speakers of L1 French do not improve overtime in their discrimination of lexical stress in L2 Spanish, and hence cannot use it as an anticipatory cue. In contrast, Cantonese and Mandarin L1 speakers can learn to discriminate lexical stress in an L2 [@chen2013chinese; @li2017effects] and Korean L1 speakers do so to a certain extent [@hualde2015acquisition; @lee2019perception] even though neither of those languages require lexical stress encoding. Whether they can use lexical stress to anticipate other linguistic information has not been researched, although other suprasegmental cues such as tones [@hed2019neural; @schremm2016implicit] suggest that L2 speakers can learn to use suprasegmental cues in an L2 to anticipate linguistic morphosyntactic information, even if this learned ability does not reach L1-like performance [@perdomo2019prosodic]. Three models have been proposed as frameworks for phonological knowledge transfer.      
  
As a recap, the literature in L2 anticipation show that speakers can achieve some success in L2 anticipation depending on the cues and the context at more advanced levels of proficiency, but their performance will not be native-like [@sagarra2018suprasegmental; @gruter2016l2]. A possible explanation for the varied results on L2 perception and anticipation might be found in what speakers are transferring or extrapolating from their L1 that interacts with L2 new structures, such as the use of lexical stress. Whereas L2 speakers’ anticipation performance might depend on their ability to perceive the cues and what needs to be anticipated, asymmetries amongst studies and the lack of cognitive measures also difficult comparison of results.      
The lack of a common theoretical framework, the use of non-standardized measures to assess proficiency [self-assessment, @lew2010real], the variety of tasks [e.g., eye-tracking, @sagarra2018suprasegmental; vs. offline, @dupoux2008persistent], a variety of L1s [@hed2019neural], and the unclear distinction of variables [@schremm2016implicit] call for further research where the possible factors accounting for L2 anticipation patterns are better distinguished. To address the limitation of confounding the L1 transfer and L2 proficiency variables, @sagarra2018suprasegmental carried out a study where the possible transfer would be the same for all participants if there was any, and found that advanced learners of English could learn to use lexical stress as anticipatory cue in L2 Spanish. In that same study, working memory did not generally explain possible individual differences. The studies reviewed above point towards the impact that cross-linguistic associations may have on the ability to process and anticipate language in an L2. However, it is yet to be found out whether the ability to process in an L2 an unencoded or differently encoded prosodic element in the L1 also enables its use for linguistic anticipation. Additionally, it is yet to be found out whether speakers associate function knowledge or acoustic knowledge from the L1 encoded representations, and how this association interacts with models of phonetic transfer.  




In this paper, we investigate whether innate abilities for rhythm and pitch and practice with correlates in the L1 affect the creation of cue-outcome associations used in speech processing. 
In particular, we asked whether better pitch and rhythm abilities affect English and Mandarin learners of Spanish at different proficiencies and monolingual speakers of Spanish to predict verb tense suffixes that are cued by lexical stress.
We included L2 speakers at different proficiencies because the ability to use lexical stress to predict tense evolves along with exposure to the L2 [@sagarra2018suprasegmental; @PRIMER EXP].
In addition, it is possible that cross-domain transfer varies over proficiency, just like other domain-general mechanisms transferred to L2 learning, such as working memory _[]_.





## 2.3. Linguistic phenomena
### 2.3.1. Lexical stress
Stress is the prominence of a syllable that speakers hear relative to the other syllables in the prosodic word [@hualde2005sounds]. The particular characteristics that define lexical stress, such as acoustic correlates or position within words, change drastically across languages. In English and Spanish, for example, lexical stress has no fixed position. Thus lexical stress is phonologically contrastive at the lexical level in both languages although to different degrees. That is, lexical stress can be used to distinguish between words, but the contrastive use is nevertheless much more typical in Spanish than in English. In English it is used predominantly to distinguish heteronyms or pairs of verbs-nouns that have no segmental differences. For instance, to “PROduce,” verb vs. “proDUCE,” noun. In Spanish, lexical stress differentiates all kinds of words and information, such as verbal tense and person ( _CANto_ 'I sing' vs. _canTÓ_ 's/he sang'), or nouns ( _PApa_ 'potato' vs. _paPÁ_ 'dad'), or nouns from verbs ( _TÉRmino_ 'term' vs. _terMIno_ 'I finish' vs. _termiNÓ_ 's/he finished').     
The acoustic realization of lexical stress is caused by different acoustic correlates depending on the language. Stress is the combined result of many parameters in action, among which we can find F0 variations, duration, overall intensity, and vowel formant frequencies [@gordon2017acoustic], and the different importances or weights assigned to each of these correlates cause the nature of stressed syllables in each language to vary. In Spanish, the most reliable cues to stress are pitch (F0), duration and intensity [@hualde2005sounds; @ortega2006phonetic; @ortega2007disentangling; @ortega2009perception]. Pitch is higher for stressed syllables and lower for unstressed syllables; regarding intensity, stressed syllables are louder; and lastly, stressed syllables are usually slightly longer. In contrast, the main cues in English are vowel duration and quality [@cooper2002constraints; @cutler1986forbear], although other cues such as intensity and pitch (F0) [@beckman1986stress; @fry1955duration; @fry1958experiments; @fry1965dependence; @sluijter1996spectral; @sluijter1997spectral] play minor roles. Thus, unstressed vowels are reduced to [ə].     
The different weight assigned to each cue in these languages may explain why L1 English speakers encounter difficulties in Spanish lexical stress perception [@face2006cognitive; @ortega2013english] and production [@lord2007role]. The different cue weights are also related to the prosodic structure of the language. Vowel reduction is linked to the rhythmic pattern of stressed-timed languages, like English, where the intervals between stressed syllables have similar durations. Spanish, on the contrary, is defined sometimes a syllable-timed language, as syllable duration is quite stable, and thus vowel trajectory length is approximately the same for all syllables regardless of their tonicity [@colantoni2015second; @hualde2005sounds]. In English, the stressed syllable signals a rhythmic unit that can be composed of multiple sub-units until the next stressed syllable and thus rhythmic unit arrives; while in Spanish, stress is simply part of a syllable, and each syllable is a new rhythmic unit.    
The different weights assigned to each cue in different languages interact with lexical stress processing particular to each language. As mentioned above, lexical stress helps activation of lexical entries in L1 Spanish [@soto2001segmental], such that a prosodically matching cue to the target ( _prinCI_ > _prinCIpio_ 'start') results in shorter and more accurate decision making times, when compared to mismatching cues ( _PRINci_ > _prinCIpio_ 'start'). These results are taken to suggest that participants in @soto2001segmental study were anticipating the lexical element based on suprasegmental cues such as lexical stress. Contrarily, it is unclear whether L1 English speakers are able to use stress alone as a cue to anticipate and facilitate lexical activation. On the one hand, @cooper2002constraints tested L1 English speakers in a similar study to that of @soto2001segmental and found that the English natives were only able to use the suprasegmental cues when more than one syllable of the word was present. On the other hand, @perdomo2019prosodic did find in an eye-tracking study that the presence of lexical stress elicited fixations on the oncoming target noun. It is possible that the L1 English speakers were using the relative low emphasis in previous syllables to activate the cue role for lexical stress in the syllables that were perceptually more prominent; similarly to what the L1 Spanish might have done, as the target words came at the end of a context sentence. This difference in performance amongst studies is probably due to what cues speakers use to discriminate lexical stress, and how these cues are instantiated in the language. That is, English L1 speakers may be placing a larger reliance on duration to process Spanish lexical stress. This reliance would be transferred from L1 English processing. Spanish L1 speakers may be relying more on other cues, such as pitch and intensity, that are discarded by the English speakers because they are not used to resorting to them, and that are more prominent in the language as compared to the one English L1 speakers are using [@ortega2013english].    
The differences and similarities in cue weighting can no doubt influence lexical stress perception in an L2. For example, @cooper2002constraints found that the similar distribution of stress in Dutch and English helped L1 Dutch learners of English transfer their knowledge of lexical stress to process it properly in L2 English. But, in contrast, German speakers have more difficulty perceiving stress in another free lexically stressed language such as Spanish than L1 speakers [@schwab2016use]; again, maybe due to the acoustic correlates they use to discriminate the suprasegmental. Following this line, @vickie2010cross suggested that language background in the L1 can affect how lexical stress is perceived in an L2 and what correlates are used to discriminate the L2 stress.    
The studies above suggest that the acoustic properties of prosody are essential in processing and activating language. The importance speakers assign to each cue might extend beyond perception and affects anticipation as well. Studies like the one by @vickie2010cross further suggest that speakers can resort to their prosodic abilities in the L1 in order to process other prosodic structures in their L2 absent in their L1, such that Chinese speakers can use pitch knowledge to discriminate lexical stress in Spanish. Extending this hypothesis, L2 speakers might be able to extrapolate acoustic knowledge and reassemble it into new prosodic structures that are encoded in the L2 lexicon and use it as cues for linguistic anticipation. Specifically, tonal language speakers might be able to transfer pitch knowledge to an L2 to encode lexical stress based primarily on pitch along with the word to which it belongs. After lexical stress has been encoded in the L2 lexicon thanks to L1 pitch knowledge, L2 speakers might learn to use this new prosodic structure as the basis for L2 prediction so as to reduce the processing cognitive load.

### 2.3.2. Tone
Tones are the pitch contour patterns of the voiced part in syllables [@chao1968grammar]. Many languages use tones, or changes in pitch-contour, at a phrasal level for pragmatic purposes. However, only a few use tones contrastively at a lexical level. The acoustic correlates for tones vary across languages: some use only pitch (e.g., Mandarin Chinese), whereas others also use length and/or register (e.g., Cantonese Chinese). Relevant to my dissertation with Mandarin Chinese speakers, in most Mandarin Chinese dialects (e.g., from Beijing and Tianjin), the main acoustic correlate for tones is changes in pitch (F0) contour or changes in pitch height within a syllable [@gandour1978perception; @zhu2015tone]. Importantly, tones in Mandarin Chinese do not cause shorter and longer syllables. Therefore, Mandarin is described as a syllable-timed language in terms of rhythm [@grabe2002durational; @lin2007mandarin; @mok2009syllable], just like Spanish.     
In Mandarin, tones facilitate word recognition [@malins2010roles]. They are nevertheless not the most important factor in that process, as vowel especially but also consonant identity comes first [@hu2012dissociation]. In other words, while tones confirm that the correct word is activated, the main vehicle to access a lexicon entry in Mandarin are other cues, mainly segmental cues. @wiener2016constraints investigated the degree to which segmental (vocalic and consonantal phonemes) and suprasegmental cues (tones) constrained lexical access in Mandarin Chinese. L1 Mandarin speakers were presented different types of stimuli containing different types of violations (tonotactic, phonactic) and had to decide as fast as possible if what they were hearing was a real word or not. Words with tonotactic violations were more often endorsed as real words than other types of violations, such as vowel or consonant change. These results led the authors to conclude that tone information is not as important as consonant and especially vowel information in lexical access. @hu2012dissociation reached a similar conclusion in a ERP study. @hu2012dissociation studied the relevance of tone and vowel information at different stages of lexical access, for which they selected fixed Chinese idioms and isolated words as context. Vowel mismatches evoked earlier (N1 effect) than tone mismatches (N400). The N1 effect was taken to suggest that vowel was playing a role on word selection, while the N400 effect signals a failure of the integration of the word in the sentential context. @sereno2015contribution obtained similar results in two priming experiments in Mandarin. Participants were slower in discriminating words where the only difference was tonal. Primings where both vowel and tone matched where the fastest one, followed by primings where only vowel matched. The three studies led to the conclusion that the functions of vowels and tones in Mandarin are distinct. Namely, that vowel plays a major role in activation, while the role of tone is integration in the higher context.       
The knowledge of the nature and function of tones in the L1 can affect L2 tone learning positively by providing a background knowledge to which learners can resort to acquire the L2 tones. However, L1 tone knowledge can also affect L2 tone learning negatively when the association with the L1 tone knowledge interferes with the nature of the L2 tones. @li2017effects examined the influence of the L1 tonal knowledge in the acquisition of L2 tones in children. These children were L1 Cantonese speakers learning L2 Mandarin, and they had issues in categorizing Mandarin tones 1 and 4, as these tones would be assimilated to the same tone 1 category in Cantonese. In the case of these children, being a native speaker to a tonal language helped them in the perception of Mandarin tones 2 and 3, but it hindered perception of other L2 tones because the knowledge association with L1 tones disagreed from the L2 tone structure and interfered with it.     
Although it seems the role of tones is not as pre-eminent of lexical stress in Spanish, it still helps in word activation and must be encoded in the lexicon. Mandarin speakers need to pay attention to the pitch variations in order to assign the correct tone to the word they are hearing. Since pitch variations are the basis for lexical stress in Spanish, Mandarin speakers might be able to extrapolate their sensitivity to pitch changes to process and use pitch to anticipate linguistic information more easily than English speakers. In English lexical stress, pitch variation is not as important as an acoustic correlate so the information it contains in an L2 is mostly overlooked by L1 English speakers. For L1 English speakers, learning to distinguish the pitch variations may be more difficult than simply extrapolating the sensitivity, and thus Mandarin speakers may outperform English speakers in using lexical stress to anticipate verbal tense in L2 Spanish.     
Lexical stress and tones are different prosodic structures with functions that may differ or not across languages. Lexical stress can be used contrastively at the lexical level, like in English, or it might not, like in French. Likewise, tones can also be contrastive, like in Mandarin. They are different prosodic structures, and lacking a representation in the L1 can hamper their acquisition in an L2. They can share, however, their acoustic correlates to some extent. Both structures make use of correlates like pitch or vowel quality to perform their function. Extrapolating this knowledge can be helpful in processing sounds in a different language. But how effective and helpful this knowledge extrapolation is might depend on the interplay of other factors, such as working memory, L2 proficiency, or other auditory abilities. 
