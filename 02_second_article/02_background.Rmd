# 1. Introduction
Transfer of skills in learning is a hot debate.
Transfer has been researched between domain-general and domain-specific mechanisms and between domain-specific mechanisms alone _[]_.
Transfer of domain-specific mechanisms alone in regards to language has been widely tested with music, for example, in learning of tones in a second language _[]_ or speech processing _[]_.
An important aspect of speech processing is prediction.
Prediction eases comprehension and processing load.
Inability to predict oncoming information and cognitive overload may thus be a source of lack of comprehension in second language learners.
While speech prediction improves with language exposure, the issue still remains how it is affected by other cognitive capacities.
In this paper, we investigate how auditory abilities condition speech prediction based on phonological cues.
Specifically, we aimed to investigate how pitch and rhythm innate abilities condition prediction of verb tense suffixes in first and second language speakers of Spanish when cued by lexically stressed and unstressed syllables.

# 2. Background
Speech is closely linked to other cognitive auditory domains.
Research with musicians has been prolific in providing evidence in support of that link.

Behavioral online studies and neurocognitive studies have revealed that musical abilities influence positively the production and perception of linguistic sound structures in adults [@wong2007musical] and L2 learners [@marques2007musicians; @slevc2006individual].
Similarly, neurocognitive studies reveal that musicians process speech in a more enhanced way and more synchronously to its onset than non-musicians [@musacchia2007musicians].     
@yu2017shared conducted a fMRI study particularly designed to test how different components of music and first language are associated.
They compared the results from a group of participants undergoing music training group and a control group in language tests (an animal-word cancellation test and an onset cancellation test) and music tests (an interval test and a rhythmic test). 
The training group performed better in all tests, and what is more, the accuracy in the animal-word cancellation test and the accuracy in the interval test were positively correlated.   

Pitch perception in particular has been associated with speech sound processing in the L1 and the L2.
Other domains, such as rhythm, have also been explored in relationship to speech, especially in the L2.

_Pitch_   
Pitch is the frequency associated to a sound wave; this frequency places the sound within a scale ranging from low to high in perception [@klapuri2006introduction]. 
Pitch in music plays a similar role to the one it plays in language. 
In language, a listener must process the melodic contour of speech, that is, the changes up and down of pitch in order to understand the meaning conveyed by prosody [@dilley2005phonetics].  
For example, a rising pitch contour signals a question (“Coffee?”), while a falling intonation signals a statement (“Coffee.”). 
Apart from the phrasal and sentential intonation, pitch also affects tones and predominance of a syllable against others within a word. 
In music, pitch affects the note we hear.    

Pitch is not only a common acoustic correlate in speech and music.
Knowledge and perception abilities of pitch in one of the two auditory domains translates in many cases into increased perception abilities in the other domain [@bidelman2013tone; @chan2019lexical], such that native speakers of tonal languages discriminate absolute pitch in music more easily [e.g., @chua2014effect; @deutsch2009absolute; @ngo2016effects; @tsukada2015perception].
Native tonal speakers, in fact, perform more similarly to musicians than to non-tonal non-musicians in most pitch and music perception tasks [@bidelman2013tone].
One exception to this association appears to be relative pitch, whose discrimination is not facilitated when through L1 tone knowledge [@ngo2016effects]. 
In turn, musicianship contributes to better lexical tone perception even in a tonal language [@tang2016musical].
Because of these results, some authors have suggested that music and language abilities transfer bidirectionally [@bidelman2013tone].

The transfer may also happen when an L2 is involved, although the effects may be weaker.
Tonal memory is significantly correlated to the skill to discriminate L2 vowels [@mokari2018perceptual], and musical knowledge contributes to L2 tone discrimination [@ngo2016effects].
However, musical knowledge does not contribute to the creation of L2 tone-segment connections when the L1 does not encode tones; only a tonal L1 promotes the creation of L2 tone-segment connections and of a rule-like system of L2 tone information [@chan2019lexical]. 
Likewise, musical ability in general is not associated with the ability to discriminate and produce L2 sounds [@mokari2018perceptual]

```

What happens with lexical stress?
Discrimination great, but processing? And ANTICIPATION?

From this set of results, it is possible to deduce that there is a limit in the reciprocal influence between music and language (musical and linguistic pitch for the purpose of this project), but where this limit lies has not been ascertained.   
   
In sum, some areas of music and language are connected, but influence from music to language and vice versa may be blocked. What these specific areas are is not completely known. While the shared processing mechanisms between music and language have been previously researched, no study so far has looked into how the anticipation mechanisms may be shared by the different auditory domains, or how the different acoustic correlates may affect anticipation in these domains. Separately, there is evidence for the existence of prediction processes in music [e.g., @salimpoor2015predictions] as well as in language. Like in language, anticipation in music can be cued through syntactic structure [@sammler2013syntax] or acoustic properties [@loui2007harmonic]. Anticipation has been particularly examined in rhythm, as synchronization to a rhythm is intrinsically keeping track of the interval structure, and therefore anticipation of the next event.

```

_Rhythm_    
Rhythm is defined as a pattern of recurrent time intervals that usually occur periodically [@berlyne1971aesthetics].
This periodic nature allows to predict the start of an interval or the next recurring event based on what has already been perceived [@fraisse2013rhythm; @martin1972rhythmic]. 
Synchronizing to a rhythm is thus anticipating when the next interval is coming and acting accordingly. 
One of the most natural ways to accompany the predicted rhythm is through movement, like body movement. This ability to anticipate events and synchronize with them is already evident in babies as young as one year of age in their rocking to musical rhythms [@fraisse1949aptitudes]. 
By the age of three or four we are able to tap along metronome beats _[]_. 


This sensorimotor behavior is based on anticipation of when the next beat is coming, especially at slow tempi [@nozaradan2016individual; @van2015sensorimotor], and the anticipation grows in accuracy with years of musical training [@nozaradan2016individual]. 
Prediction of oncoming beats is also present in rhythms with tempo changes [@van2015sensorimotor].   
The ability to synchronize to beats or changes in rhythm is conditioned by (1) motor limits, (2) the fractured memory of a slow sequence, (3) sensory difficulties at perceiving successiveness at fast tempi [@bartlett1959synchronization], and (4) the complexity of the rhythm [@fraisse2012anticipation].However, the adaptation is fast, since it can take as few as three consecutive taps accompanying each a consecutive beat in a novel rhythm to achieve a relative simultaneity [@fraisse2012anticipation]. The rhythm structure affects the synchronization pattern, as some tempo speeds are easier to adjust to than others. When the interval between beats is on or under 1500 ms, the synchronization behavior tends towards anticipation of the next beat, while this anticipation rate starts to decrease with beat onset intervals of 1800 ms [@miyake2004two].  

Within the auditory modality, music is probably the most obvious instance of rhythm, but other domains such as language also follow rhythmic patterns.
This similarity may involve shared cognitive mechanisms to perceive and process rhythm in different domains.
If the mechanisms are shared, then increased abilities in rhythm, be them innate or acquired through practice, may have an effect on discrimination and processing of rhythms in language.
Indeed, rhythmic abilities and perception condition L1 and L2 processing. 
Matching metrical primes facilitate processing of sentences in the L1 _[@cason2015]_.
ERP recordings have shown that on-beat sequence primes result in faster L1 speech processing than off-beat primes in adults _[@cason201]_. Rhythmic production is positively associated with L2 lexical stress placement and rhythm perception with the L2 learning experience [@bhatara2015foreign; @cason2019rhythmic].
Better increased rhythmic perception, in contrast, is not associated with adults' reading abilities in an L1 or L2 [@swaminathan2018explaining].
Swaminathan and colleagues were, nevertheless, mixing modalities (written text and heard rhythms), while Cason and colleagues were not. 
We could therefore hypothesize that a relationship between speech and rhythm is still not precluded.
This conclusion would also agree with with association learning models proposing that the more similar two cognitive specific domains are, the likelier the transfer of abilities and mechanisms between them is.

```
Link to speech anticipation

```

In this paper, we investigate whether innate abilities for rhythm and pitch and practice with correlates in the L1 affect the creation of cue-outcome associations used in speech processing. 
In particular, we asked whether better pitch and rhythm abilities affect English and Mandarin learners of Spanish at different proficiencies and monolingual speakers of Spanish to predict verb tense suffixes that are cued by lexical stress.
We included L2 speakers at different proficiencies because the ability to use lexical stress to predict tense evolves along with exposure to the L2 [@sagarra2018suprasegmental; @PRIMER EXP].
In addition, it is possible that cross-domain transfer varies over proficiency, just like other domain-general mechanisms transferred to L2 learning, such as working memory _[]_.



## 2.1. Anticipation
Anticipation alleviates the load of constantly processing the information that we receive from the world. At a large scale, we anticipate what is going to happen in movies and books. At smaller scales, we anticipate movements in sports, other drivers' actions, and we also anticipate what we read and what we hear. In non-linguistic auditory domains, like music, we anticipate the melody through pitch and rhythm. In non-linguistic visuospatial anticipation, we use the position and movement of objects to anticipate how long it will take an object to reach a certain point, or to anticipate the trajectory it is following. Finally, in linguistic anticipation, we use cues of different kinds (contextual, phonological, morphosyntactic) to predict oncoming linguistic information. Predictive processing in language is especially efficient in the L1, and mediated by factors such as L1 transfer, L2 proficiency, or working memory in the L2. These factors may interact with each other to generate successful or unsuccessful predictions.

### 2.1.2. Linguistic anticipation
In this project, I adopt a predictive processing view of language. That is, language processing is facilitated and preceded by prediction of linguistic information based on the already available information, which acts as prediction cues. The underlying mechanisms of how prediction works are still a matter of debate. Linguistic prediction might well be domain-specific, but research on populations with reduced/loaded executive resources resulting in underachieved prediction suggests that linguistic anticipation is actually related to more general cognitive resources. Thus, children’s executive resources do not reach maturity until early adulthood [@davidson2006development; @de2010developmental]; this lack of cognitive development has been used to account for their an inability to predict linguistic correctly [e.g., @friedrich2005phonotactic; @gambi2018development]. On the other end, the executive functions in adults over 45 years of age have already declined enough to slow prediction [e.g., @dagerman2006aging; @federmeier2019s]. In a different context, L2 learners [e.g., @lew2010real; @mitsugi2016use] load the pool of executive functions that they would otherwise use for anticipation in their L1 [@linck2014working], although in their case, lack of prior linguistic experience also affect their ability to generate linguistic predictions [@cuetos1996parsing]. Lack of enough language experience as a factor determining anticipation performance could naturally be applied to children to. Similarly, even adults in their L1 constantly readapt their expectations based on previous linguistic input [e.g., @levy2008expectation; @ryskin2017verb].     

#### 2.1.2.1. L1 speakers
Just like in any other realm of life, humans tend to anticipate linguistic information. We anticipate semantic [@altmann1999incremental] and morphosyntactic [@gruter2016l2; @lew2010real] information by using morphosyntactic [@gruter2016l2], syntactic [@linzen2016uncertainty], semantic [@kamide2003time; @pozzan2016semantic] and phonological cues. Relevant to my dissertation, the phonological cues that speakers may use to anticipate in their L1 are numerous: coarticulation [@salverda2014immediate], intonation [@nakamura2012immediate; @weber2006role], lexical stress [@correia2013word; @sagarra2018suprasegmental], pauses between clauses [@hawthorne2014pauses; @kjelgaard1999prosodic], vowel duration [@rehrig2017acoustic], and tone [@roll2015neurolinguistic; @roll2011activating].    
Linguistic prediction allows listeners to anticipate upcoming words and regions [@brennan2019hierarchical; @yang2019clause], and word endings [@roll2010word; @sagarra2018suprasegmental; @soto2001segmental]. Here, I will focus briefly on suffix prediction. Predictions of morphosyntactic elements can be generated through determiners [in Dutch, @huettig2016prediction; in Spanish, @dussias2013gender; @lew2010real; in German, @hopp2013grammatical; in French, @dahan2000linguistic]. Determiners can provide information about number [@marull2017second], gender [@dahan2000linguistic], and case [German @hopp2015semantics; Japanese, @mitsugi2016use].     
Within the very word containing the suffix to be predicted, phonological information such as tone or lexical stress can cue the generation of the correct anticipation of word endings. Swedish speakers use tonal cues to predict noun number [if low tone, then singular, _fisken_ 'fish~[SG]~'; if high tone, then plural, _fiskar_ 'fish~[PL]~,' @roll2010word; @soderstrom2015using; @roll2013word] and verb tense [if low tone, then present, _skrämmer_ 'I scare'; if high tone, then past, _skrämde_ 'I scared,' @soderstrom2012processing; @roll2015neurolinguistic]. Similarly, Spanish speakers use lexical stress to predict verbal tense [if first syllable stressed, then present; if unstressed, then past: _CANta_ 'he sings' vs. _canTÓ_ 'he sang,' @sagarra2018suprasegmental] and noun ending [ _PRINcipe_ 'prince' vs. _prinCIPIO_ 'beginning,' @soto2001segmental]. Finally, English natives use vowel duration to predict voice [if shorter vowel duration, then active: 'the girl was pushing the boy'; if longer vowel duration, then passive: 'the girl was pushed by the boy,' @rehrig2017acoustic].    
Although findings on anticipation in L1 show that typical L1 speakers tend to perform predictive language processing, it is unclear how individual variability in cognitive capacities, i.e. working memory, can affect the efficacy of the predictions. @huettig2016prediction found through eye-tracking that the variance between participants in fixating on the correct target noun based on gendered article in Dutch could be accounted for working memory. However, @sagarra2018suprasegmental found also by means of eye-tracking that working memory played no role, or a marginal one, in L1 Spanish speakers’ capacity to anticipate verbal tense based on lexical stress. Similarly, @otten2009does found no effect of working memory on L1 anticipation in an ERP study. It is difficult to interpret these results, as whereas the technique was the same in the eye-tracking studies, the domains under research cannot explain the differences. @sagarra2018suprasegmental found none focusing on the role of prosodic cues, and @huettig2016prediction found a working memory effect focusing on the role of morphosyntactic information, but @otten2009does found no effect either also focusing on the role of morphosyntactic information but using a different online method. It is possible that different levels of linguistic complexity interact with behavioral or brain activity performance, and only in certain cases the impact of differences in working memory capacities are visible in linguistic anticipation. However, the scant amount of research on the interaction between linguistic anticipation and working memory capacities forces to make interpretations of the findings so far with caution.

#### 2.1.2.2. L2 speakers
Anticipation in L2 speakers is controversial because different studies revealed different findings. Particularly in morphosyntactic anticipation, some studies find that L2 speakers can generate predictions [@dussias2013gender], while others have found they cannot [@hopp2016learning], or only in certain situations [@lew2010real] or specific levels of proficiency [@sagarra2018suprasegmental]. Two of the factors that could account for the variability in L2 anticipation performance and that often appear together are proficiency and cross-linguistic differences. Another factor that could explain the ability to predict in an L2 or not is whether morphosyntax is the cue, the outcome, or both.
It is difficult to disentangle the influence of L1 transfer and L2 proficiency because they are often confounded variables in studies lacking language pairs with different L1s. Furthermore, the combination of L1 transfer and L2 proficiency can happen at different levels of linguistic processing, from the smaller parts like morphology to higher-order levels. At higher-order levels research is very scant. @gruter2013l2, @gruter2014role and @gruter2016l2 explored whether L1 speakers of Korean or Japanese could anticipate the correct oncoming syntactic structure in the discourse in L2 English based on coreference. While L2 speakers were sensitive to the cue, they did not use it to anticipate the structure of the syntactic event. At lower levels where phonology and morphosyntax are involved, there is some more research.   
Aticipation of and based on morphosyntax in an L2 has been tested primarily with gender [e.g., @hopp2013grammatical]. As opposed to L1 anticipation, however, morphosyntactic anticipation in the L2 is determined by the listener's proficiency in the L2 [@sagarra2018suprasegmental] and their L1. The L1 linguistic system can both help [@dussias2013gender] and hinder [@dupoux2008persistent] L2 processing. 
In L2 morphosyntactic anticipation, the gender in the determiner is a reliable cue to gender suffixes in nouns, although some restrictions apply. In L2 German, determiner gender is reliable if the L2 speaker uses the gender system target-like [@hopp2013grammatical; @hopp2016learning]. In L2 Spanish, predictions may be generated if the L1 also has a gender system [@dussias2013gender], or in case the L1 lacks a gender system, if the predictions are to be made on novel nouns [@gruter2013l2], or if the nouns are highly frequent [@lew2010real]. Other morphosyntactic elements such as number are not as reliable as cues [@marull2017second], and for others, like case, the cue-outcome connection is directly not created [@hopp2015semantics; @mitsugi2016use].     
In morphosyntactic anticipation other factors might be at play, like L1 transfer and L2 proficiency. The workings of these factors start at lower levels of proficiency. @dussias2013gender examined L1 Italian and L1 English learners of L2 Spanish’s ability to use gender agreement as an anticipation cue. L1 Italian speakers could make use of the gender cue partially to make agreement anticipations at lower levels of proficiency, whereas L1 English speakers could not. L1 English speakers can only start to use gender as a cue at high-intermediate levels, under frequency or novelty conditions of the noun [@gruter2013l2; @lew2010real, respectively]. Italian speakers were presumably transferring their gender agreement knowledge from the L1 to the L2 in order to make the correct predictions. English speakers, however, lack this knowledge in their L1 so no extrapolation was possible. Additionally, it has been argued that lacking the representation of gender marking in the L1 might not only prevent prediction in an L2 based on that cue, but also hinder it [@hopp2016learning]. This proposal fits with @lew2010real findings that L1 English speakers at an intermediate level of proficiency cannot use gender marking to anticipate oncoming nouns in L2 Spanish, but they can use definiteness in articles to anticipate known nouns.     
While gender has been the cue more widely researched, but shared forms, number and case have also been included in past investigations. Having a similar system in terms of form can be helpful. @liburd2014investigating examined the abilities of beginning learners of L2 Dutch with English as L1 to use determiners with similar, different, and unique forms in English and Dutch to anticipate nouns. The eye-tracking data collected suggest that the English speakers were faster and more accurate in generating their predictions when the form was similar in their L1 and L2. Apart from gender, the influence of L2 proficiency is also visible in other cues such as number. Intermediate English speakers of L2 Spanish cannot use number to anticipate numbers suffix in a noun but advanced speakers can [@marull2017second]. In the case of case, the difficulty is never overcome, regardless of the L2 speaker's proficiency [@hopp2015semantics]. In Hopp's study, the L1 of the speakers was English. Like with gender, lacking a case system representation in the L1 might be preventing, and even hindering, the creation of case cue-suffix outcome connection.      
The conclusion that lack of L1 representation prevents L2 anticipation might only be applicable to morphosyntactic cases, or cases of lower proficiency, as it does not account for anticipatory behavior regarding phonology. @rehrig2017acoustic investigated whether L2 speakers could use suprasegmental information in a word stem like vowel lengthening to predict its suffix when their L1 lacked representation for those phenomena. They found that proficient L2 speakers did use the suprasegmental information, but learners at lower proficiencies did not. Similar studies focusing on tone have yielded similar results [e.g. @schremm2016implicit; @berthelsen2018neural].       
When the acoustic correlate does have a representation in the L1 but it differs from the one typical in the L2, results become messier. On the one hand, @sagarra2018suprasegmental found that L1 English speakers with advanced L2 Spanish could use lexical stress as a cue to anticipate verbal endings when the stress appeared in CVC syllables but not in CV syllables, and L2 Spanish beginners could not use stress to anticipate verb suffixes in either case. On the other hand, @dupoux2008persistent found that speakers of L1 French do not improve overtime in their discrimination of lexical stress in L2 Spanish, and hence cannot use it as an anticipatory cue. In contrast, Cantonese and Mandarin L1 speakers can learn to discriminate lexical stress in an L2 [@chen2013chinese; @li2017effects] and Korean L1 speakers do so to a certain extent [@hualde2015acquisition; @lee2019perception] even though neither of those languages require lexical stress encoding. Whether they can use lexical stress to anticipate other linguistic information has not been researched, although other suprasegmental cues such as tones [@hed2019neural; @schremm2016implicit] suggest that L2 speakers can learn to use suprasegmental cues in an L2 to anticipate linguistic morphosyntactic information, even if this learned ability does not reach L1-like performance [@perdomo2019prosodic]. Three models have been proposed as frameworks for phonological knowledge transfer.      
The models that have been proposed to account for cross-linguistic phonological effects were designed particularly with phoneme production in mind. However, it is possible to extend some of their tenets to provide a framework with which to study transfer and comprehension of suprasegmental information. Here I am going to describe those tenets relevant for this investigation. The three models are the Speech Learning Model [SLM, @flege1995second], the Perceptual Assimilation Model for L2 [PAM-L2, @best1995learning; @best2007nonnative], and the Second Language Linguistic Perception [L2LP, @escudero2005linguistic; @escudero2009linguistic; @leussen2015learning]. SLM focuses on ultimate attainment of L2 phonology and how age constraints target-like phonological succes in an L2. In this model, a speaker can exploit the same mechanisms and processes they used in the acquisition of their L1 phonological system to acquire the L2 sound system. The language-specific characteristics of sounds are encoded in the long-term memory, and the encoding and different speech categories in the long-term memory evolve with L1 and L2 knowledge to reflect the realization of sounds on both languages. Lastly, bilinguals differentiate the co-existing L1 and L2 phonetic categories. From these postulates, Flege elaborated on seven hypotheses regarding phoneme categorization and production in the L2. Two of these hypotheses are relevant for this project. First, a L1 phonetic category can block the creation of a similar category in the L2 due to equivalent classification. Therefore, the L1 phonetic category will be used to perceive sounds in both the L1 and the L2. Second, the L2 phonetic categories may present different characteristics from what L1 phonetic categories of than language present for two reasons, either the speaker is trying to keep the L2 category "deflected" from a category in their L1 in the common phonological space, or the L2 category in a bilingual speaker is characterized with different features or weights than the L1 category in a monolingual speaker.     
PAM-L2 was originally proposed to account for L1 phonological acquisition, but it later morphosed to account for L2 phonological development. Like in SLM, age of the speaker determines L2 perception learning, as well as other social factors, such as length of residence in an L2 environment. Importantly for this project, L2 perception in this model is going to be constrained by nonnative speech perception principles, that is, how similar or different the new sounds are compared to an already established sound system. L2 sounds can thus be assimilated to a L1 category, assimilated as uncategorizable to an existing sound, or discarded for being considered non-speech sounds. The last model is L2LP. This is the only one among the three models that was thought out to explain and predict L2 sound perception phenomena. In L2LP, L2 sounds are perceived through the L1 filter, that is, how they would be perceived if they were pronounced in the speaker's L1. Therefore, the acoustic similarities and discrepancies between the two phonological systems will shape the development of the encoding in the bilingual's mind. In L2 sound acquisition, a copy of the L1 system is created during the initial stages, this copy starts to adjust with exposure via the Gradual Learning Algorithm, a comparison of the L1 system and the perceived L2 sounds. The algorithm offers three possibilities: a new sound is assimilated to multiple L1 sounds, a new sound is perceived as similar to another one in the L1 system, or a new sound does not equal any category in the L1 so it requires a new category for itself. Recent revisions to the model have further proposed that perceiving is not the same thing as recognizing, but there is still not enough research in this direction to formulate any hypothesis.     
As a recap, the literature in L2 anticipation show that speakers can achieve some success in L2 anticipation depending on the cues and the context at more advanced levels of proficiency, but their performance will not be native-like [@sagarra2018suprasegmental; @gruter2016l2]. A possible explanation for the varied results on L2 perception and anticipation might be found in what speakers are transferring or extrapolating from their L1 that interacts with L2 new structures, such as the use of lexical stress. Whereas L2 speakers’ anticipation performance might depend on their ability to perceive the cues and what needs to be anticipated, asymmetries amongst studies and the lack of cognitive measures also difficult comparison of results.      
The lack of a common theoretical framework, the use of non-standardized measures to assess proficiency [self-assessment, @lew2010real], the variety of tasks [e.g., eye-tracking, @sagarra2018suprasegmental; vs. offline, @dupoux2008persistent], a variety of L1s [@hed2019neural], and the unclear distinction of variables [@schremm2016implicit] call for further research where the possible factors accounting for L2 anticipation patterns are better distinguished. To address the limitation of confounding the L1 transfer and L2 proficiency variables, @sagarra2018suprasegmental carried out a study where the possible transfer would be the same for all participants if there was any, and found that advanced learners of English could learn to use lexical stress as anticipatory cue in L2 Spanish. In that same study, working memory did not generally explain possible individual differences. The studies reviewed above point towards the impact that cross-linguistic associations may have on the ability to process and anticipate language in an L2. However, it is yet to be found out whether the ability to process in an L2 an unencoded or differently encoded prosodic element in the L1 also enables its use for linguistic anticipation. Additionally, it is yet to be found out whether speakers associate function knowledge or acoustic knowledge from the L1 encoded representations, and how this association interacts with models of phonetic transfer.  

## 2.3. Linguistic phenomena
### 2.3.1. Lexical stress
Stress is the prominence of a syllable that speakers hear relative to the other syllables in the prosodic word [@hualde2005sounds]. The particular characteristics that define lexical stress, such as acoustic correlates or position within words, change drastically across languages. In English and Spanish, for example, lexical stress has no fixed position. Thus lexical stress is phonologically contrastive at the lexical level in both languages although to different degrees. That is, lexical stress can be used to distinguish between words, but the contrastive use is nevertheless much more typical in Spanish than in English. In English it is used predominantly to distinguish heteronyms or pairs of verbs-nouns that have no segmental differences. For instance, to “PROduce,” verb vs. “proDUCE,” noun. In Spanish, lexical stress differentiates all kinds of words and information, such as verbal tense and person ( _CANto_ 'I sing' vs. _canTÓ_ 's/he sang'), or nouns ( _PApa_ 'potato' vs. _paPÁ_ 'dad'), or nouns from verbs ( _TÉRmino_ 'term' vs. _terMIno_ 'I finish' vs. _termiNÓ_ 's/he finished').     
The acoustic realization of lexical stress is caused by different acoustic correlates depending on the language. Stress is the combined result of many parameters in action, among which we can find F0 variations, duration, overall intensity, and vowel formant frequencies [@gordon2017acoustic], and the different importances or weights assigned to each of these correlates cause the nature of stressed syllables in each language to vary. In Spanish, the most reliable cues to stress are pitch (F0), duration and intensity [@hualde2005sounds; @ortega2006phonetic; @ortega2007disentangling; @ortega2009perception]. Pitch is higher for stressed syllables and lower for unstressed syllables; regarding intensity, stressed syllables are louder; and lastly, stressed syllables are usually slightly longer. In contrast, the main cues in English are vowel duration and quality [@cooper2002constraints; @cutler1986forbear], although other cues such as intensity and pitch (F0) [@beckman1986stress; @fry1955duration; @fry1958experiments; @fry1965dependence; @sluijter1996spectral; @sluijter1997spectral] play minor roles. Thus, unstressed vowels are reduced to [ə].     
The different weight assigned to each cue in these languages may explain why L1 English speakers encounter difficulties in Spanish lexical stress perception [@face2006cognitive; @ortega2013english] and production [@lord2007role]. The different cue weights are also related to the prosodic structure of the language. Vowel reduction is linked to the rhythmic pattern of stressed-timed languages, like English, where the intervals between stressed syllables have similar durations. Spanish, on the contrary, is defined sometimes a syllable-timed language, as syllable duration is quite stable, and thus vowel trajectory length is approximately the same for all syllables regardless of their tonicity [@colantoni2015second; @hualde2005sounds]. In English, the stressed syllable signals a rhythmic unit that can be composed of multiple sub-units until the next stressed syllable and thus rhythmic unit arrives; while in Spanish, stress is simply part of a syllable, and each syllable is a new rhythmic unit.    
The different weights assigned to each cue in different languages interact with lexical stress processing particular to each language. As mentioned above, lexical stress helps activation of lexical entries in L1 Spanish [@soto2001segmental], such that a prosodically matching cue to the target ( _prinCI_ > _prinCIpio_ 'start') results in shorter and more accurate decision making times, when compared to mismatching cues ( _PRINci_ > _prinCIpio_ 'start'). These results are taken to suggest that participants in @soto2001segmental study were anticipating the lexical element based on suprasegmental cues such as lexical stress. Contrarily, it is unclear whether L1 English speakers are able to use stress alone as a cue to anticipate and facilitate lexical activation. On the one hand, @cooper2002constraints tested L1 English speakers in a similar study to that of @soto2001segmental and found that the English natives were only able to use the suprasegmental cues when more than one syllable of the word was present. On the other hand, @perdomo2019prosodic did find in an eye-tracking study that the presence of lexical stress elicited fixations on the oncoming target noun. It is possible that the L1 English speakers were using the relative low emphasis in previous syllables to activate the cue role for lexical stress in the syllables that were perceptually more prominent; similarly to what the L1 Spanish might have done, as the target words came at the end of a context sentence. This difference in performance amongst studies is probably due to what cues speakers use to discriminate lexical stress, and how these cues are instantiated in the language. That is, English L1 speakers may be placing a larger reliance on duration to process Spanish lexical stress. This reliance would be transferred from L1 English processing. Spanish L1 speakers may be relying more on other cues, such as pitch and intensity, that are discarded by the English speakers because they are not used to resorting to them, and that are more prominent in the language as compared to the one English L1 speakers are using [@ortega2013english].    
The differences and similarities in cue weighting can no doubt influence lexical stress perception in an L2. For example, @cooper2002constraints found that the similar distribution of stress in Dutch and English helped L1 Dutch learners of English transfer their knowledge of lexical stress to process it properly in L2 English. But, in contrast, German speakers have more difficulty perceiving stress in another free lexically stressed language such as Spanish than L1 speakers [@schwab2016use]; again, maybe due to the acoustic correlates they use to discriminate the suprasegmental. Following this line, @vickie2010cross suggested that language background in the L1 can affect how lexical stress is perceived in an L2 and what correlates are used to discriminate the L2 stress.    
The studies above suggest that the acoustic properties of prosody are essential in processing and activating language. The importance speakers assign to each cue might extend beyond perception and affects anticipation as well. Studies like the one by @vickie2010cross further suggest that speakers can resort to their prosodic abilities in the L1 in order to process other prosodic structures in their L2 absent in their L1, such that Chinese speakers can use pitch knowledge to discriminate lexical stress in Spanish. Extending this hypothesis, L2 speakers might be able to extrapolate acoustic knowledge and reassemble it into new prosodic structures that are encoded in the L2 lexicon and use it as cues for linguistic anticipation. Specifically, tonal language speakers might be able to transfer pitch knowledge to an L2 to encode lexical stress based primarily on pitch along with the word to which it belongs. After lexical stress has been encoded in the L2 lexicon thanks to L1 pitch knowledge, L2 speakers might learn to use this new prosodic structure as the basis for L2 prediction so as to reduce the processing cognitive load.

### 2.3.2. Tone
Tones are the pitch contour patterns of the voiced part in syllables [@chao1968grammar]. Many languages use tones, or changes in pitch-contour, at a phrasal level for pragmatic purposes. However, only a few use tones contrastively at a lexical level. The acoustic correlates for tones vary across languages: some use only pitch (e.g., Mandarin Chinese), whereas others also use length and/or register (e.g., Cantonese Chinese). Relevant to my dissertation with Mandarin Chinese speakers, in most Mandarin Chinese dialects (e.g., from Beijing and Tianjin), the main acoustic correlate for tones is changes in pitch (F0) contour or changes in pitch height within a syllable [@gandour1978perception; @zhu2015tone]. Importantly, tones in Mandarin Chinese do not cause shorter and longer syllables. Therefore, Mandarin is described as a syllable-timed language in terms of rhythm [@grabe2002durational; @lin2007mandarin; @mok2009syllable], just like Spanish.     
In Mandarin, tones facilitate word recognition [@malins2010roles]. They are nevertheless not the most important factor in that process, as vowel especially but also consonant identity comes first [@hu2012dissociation]. In other words, while tones confirm that the correct word is activated, the main vehicle to access a lexicon entry in Mandarin are other cues, mainly segmental cues. @wiener2016constraints investigated the degree to which segmental (vocalic and consonantal phonemes) and suprasegmental cues (tones) constrained lexical access in Mandarin Chinese. L1 Mandarin speakers were presented different types of stimuli containing different types of violations (tonotactic, phonactic) and had to decide as fast as possible if what they were hearing was a real word or not. Words with tonotactic violations were more often endorsed as real words than other types of violations, such as vowel or consonant change. These results led the authors to conclude that tone information is not as important as consonant and especially vowel information in lexical access. @hu2012dissociation reached a similar conclusion in a ERP study. @hu2012dissociation studied the relevance of tone and vowel information at different stages of lexical access, for which they selected fixed Chinese idioms and isolated words as context. Vowel mismatches evoked earlier (N1 effect) than tone mismatches (N400). The N1 effect was taken to suggest that vowel was playing a role on word selection, while the N400 effect signals a failure of the integration of the word in the sentential context. @sereno2015contribution obtained similar results in two priming experiments in Mandarin. Participants were slower in discriminating words where the only difference was tonal. Primings where both vowel and tone matched where the fastest one, followed by primings where only vowel matched. The three studies led to the conclusion that the functions of vowels and tones in Mandarin are distinct. Namely, that vowel plays a major role in activation, while the role of tone is integration in the higher context.       
The knowledge of the nature and function of tones in the L1 can affect L2 tone learning positively by providing a background knowledge to which learners can resort to acquire the L2 tones. However, L1 tone knowledge can also affect L2 tone learning negatively when the association with the L1 tone knowledge interferes with the nature of the L2 tones. @li2017effects examined the influence of the L1 tonal knowledge in the acquisition of L2 tones in children. These children were L1 Cantonese speakers learning L2 Mandarin, and they had issues in categorizing Mandarin tones 1 and 4, as these tones would be assimilated to the same tone 1 category in Cantonese. In the case of these children, being a native speaker to a tonal language helped them in the perception of Mandarin tones 2 and 3, but it hindered perception of other L2 tones because the knowledge association with L1 tones disagreed from the L2 tone structure and interfered with it.     
Although it seems the role of tones is not as pre-eminent of lexical stress in Spanish, it still helps in word activation and must be encoded in the lexicon. Mandarin speakers need to pay attention to the pitch variations in order to assign the correct tone to the word they are hearing. Since pitch variations are the basis for lexical stress in Spanish, Mandarin speakers might be able to extrapolate their sensitivity to pitch changes to process and use pitch to anticipate linguistic information more easily than English speakers. In English lexical stress, pitch variation is not as important as an acoustic correlate so the information it contains in an L2 is mostly overlooked by L1 English speakers. For L1 English speakers, learning to distinguish the pitch variations may be more difficult than simply extrapolating the sensitivity, and thus Mandarin speakers may outperform English speakers in using lexical stress to anticipate verbal tense in L2 Spanish.     
Lexical stress and tones are different prosodic structures with functions that may differ or not across languages. Lexical stress can be used contrastively at the lexical level, like in English, or it might not, like in French. Likewise, tones can also be contrastive, like in Mandarin. They are different prosodic structures, and lacking a representation in the L1 can hamper their acquisition in an L2. They can share, however, their acoustic correlates to some extent. Both structures make use of correlates like pitch or vowel quality to perform their function. Extrapolating this knowledge can be helpful in processing sounds in a different language. But how effective and helpful this knowledge extrapolation is might depend on the interplay of other factors, such as working memory, L2 proficiency, or other auditory abilities. 