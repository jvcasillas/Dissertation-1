# 1. Introduction
Adults have difficulties in learning a second language (L2).
We draw from our previous knowledge to support the learning process and make up for the shortcomings we have in our L2.
The previous knowledge does not have to be linguistic.
Musicians native to non-tonal L1s, for example, rely on their musical skills to discriminate L2 tones [@tang2016musical].
While we may transfer non-linguistic skills to aid in L2 perception, it is still unknown what the effects of transfer is in linguistic processing.
In particular, it is still unclear what previous knowledge we can transfer during L2 learning and processing, under what circumstances transfer may take place, and what the effects are.
In addition, the previous research has focused on populations who had developed a non-linguistic skill but ignored the role of innate abilities, which may account for individual differences in L2 processing.
The transfer of innate abilities could take place between domain-general and domain-specific mechanisms and between domain-specific mechanisms alone.
_Transfer of domain-specific mechanisms alone in regards to language has been widely tested with music, or in speech processing [e.g., @dittinger2016professional; @fitzroy2013musical; @musacchia2007musicians]._
_In speech processing, anticipation of information is crucial because it eases comprehension and processing load._
_Inability to predict oncoming information and cognitive overload may be a source of lack of comprehension in second language learners._
_While speech prediction improves with language exposure [e.g., _@Primerexperimento_, _@sagarra2018suprasegmental], the issue still remains how speech processing is affected by other cognitive capacities._

In this paper, we investigate how auditory abilities are transferred and may condition speech prediction in a first language (L1) and in an L2.
Specifically, we investigate how pitch and rhythm innate abilities condition prediction of verb tense suffixes in L1 and L2 speakers of Spanish when cued by lexically stressed and unstressed syllables.
To observe the interaction between innate rhythmic abilities and speech prediction skills, we tested monolingual speakers (Spanish), speakers whose L1 is of the same rhythmic category as the L2 (Mandarin Chinese-Spanish, both syllable-timed), and speakers whose L1 and L2 are rhythmically different (English-Spanish, English is stress-timed). 
To observe the interaction between innate pitch abilities and pitch prediction skills, we also compare the monolingual group with speakers whose L1 and L2 share the use of pitch height for lexical stress (English-Spanish), and with speakers whose L1 and L2 use pitch differently and for different purposes (Chinese uses pitch contour for lexical tone; Spanish uses pitch height for lexical stress). 

# 2. Background
## 2.1. Linguistic prediction
In linguistic prediction, a cue is associated to an outcome. 
The mental representation of this association facilitates processing. 
The association may be established at different levels: _mention some_
The lack of the mental representation has been suggested as a possible cause for the difficulty that native speakers of morphologically-poorer languages have in processing morphologically-richer L2s [@sagarra2018suprasegmental].
Lacking this mental representation would cause processing difficulty because there is no pre-activation of morphological elements. Therefore all morphemes need to be paid careful attention to, which, given their typical less saliency, results cognitive taxation, slower processing and incomplete comprehension.

Research on the association of lexical stress-verb tense suffix initially supports the idea that lacking a represented association hinders processing.
L1 English speakers need to reach advanced proficiency to acquire the lexical stress-verb tense suffix and use it for prediction, although they can only apply the association when the cue appears on CVC syllables (*FIRma-firMÓ*, 's/he signs-s/he signed) and not CV syllables [*LAva-laVÓ*, 's/he washes-s/he washed', @sagarra2018suprasegmental].
The syllable structure effect does not disappear even in proficient speakers who make out of prediction a way of living, i.e., interpreters [@lozano2019slowly].
For CVC syllables, however, the creation of an association can be accelerated when the speaker lives immersed in the L2 [@PRIMEREXPERIMENTO].
The facilitating effect of immersion has also been ascertained with pitch accent and noun number suffixes for the most part _[@gosselke-berthelsen2018; @hed2019; @schremm2017]_, although also with verb tense suffixes to some extent in Central Swedish _[@schremm2016]_.
The studies on predictive processing of suffixes based on pitch accent in Central Swedish generally suggest, likewise, that the longer the exposure and the higher the proficiency the better the predictive performance.

While linguistic factors such as syllable structure or immersion may affect speakers' abilities to create cue-outcome associations based on phonological and morphological structures, other factors may be at play.
Individual differences are responsible of the different degrees of sensitivity to lexical stress in L1 French-L2 Spanish speakers [@dupoux2008].
Trying to delve into individual differences in prediction, @sagarra2018suprasegmental tested whether they were due to verbal working memory capacity.
In their study, verbal working memory did not predict the ability of either monolinguals or bilinguals at different levels of proficiency to anticipate tense based on lexical stress.
Whereas domain-general mechanisms such as working memory have been more typically considered as sources of individual variability, their relationship with language processing is unclear.
Additionally, domain-specific mechanisms not pertaining to language have rarely been included as factors conditioning language acquisition and processing, which however, have been proven to be important in language perception.
Here, we address this neglect by examining the relationship between innate auditory abilities in the form of pitch and rhythm and speech anticipation.

## 2.2. Music and speech
Research with musicians has been prolific in providing evidence in support of the link between speech and music.
Behavioral online studies and neurocognitive studies have revealed that musical abilities influence positively the production and perception of linguistic sound structures in monolingual adults [@wong2007musical] and L2 learners [@marques2007musicians; @slevc2006individual].
Similarly, neurocognitive studies reveal that musicians process speech in a more enhanced way and more synchronously to its onset than non-musicians [e.g., @dittinger2016professional; @fitzroy2013musical; @musacchia2007musicians]. 
In a meta-analysis, @kraus2010music concluded that music training can cause functional and structural changes in the brain.
Brain changes caused by music training may translate into improvement in language performance as music shares with language physiological resources that process auditory information.
Given that music and language share physiological resources and that musical practice gives an advantage in speech processing and in L2 acquisition, the relationship between both domains may extend further than training.
In other words, varying innate abilities may be responsible for individual variation of L2 processing, in particular of phonology, among learners of L2s.
Since music is a broad term, here we will focus on pitch, rhythm and their relationship with speech processing in an L1 and an L2.

_Pitch_   
Pitch is the frequency associated to a sound wave; this frequency places the sound within a scale ranging from low to high in perception [@klapuri2006introduction]. 
Pitch in music plays a similar role to the one it plays in language. 
In language, a listener must process the melodic contour of speech, that is, the changes up and down of pitch in order to understand the meaning conveyed by prosody [@dilley2005phonetics].  
For example, a rising pitch contour signals a question (“Coffee?”), while a falling intonation signals a statement (“Coffee.”). 
Apart from the phrasal and sentential intonation, pitch also affects tones and predominance of a syllable against others within a word. 
In music, pitch affects the note we hear.    

Pitch is not only a common acoustic correlate in speech and music.
Knowledge and perception abilities of pitch in one of the two auditory domains translates in many cases into increased perception abilities in the other domain [@bidelman2013tone; @chan2019lexical], such that native speakers of tonal languages discriminate absolute pitch in music more easily [e.g., @chua2014effect; @deutsch2009absolute; @ngo2016effects; @tsukada2015perception].
Native tonal speakers, in fact, perform more similarly to musicians than to non-tonal non-musicians in most pitch and music perception tasks [@bidelman2013tone].
One exception to this association appears to be relative pitch, whose discrimination is not facilitated when through L1 tone knowledge [@ngo2016effects]. 
In turn, musicianship contributes to better lexical tone perception even in a tonal language [@tang2016musical].
Because of these results, some authors have suggested that music and language abilities transfer bidirectionally [@bidelman2013tone].

The transfer may also happen when an L2 is involved, although the effects may be weaker.
Tonal memory is significantly correlated to the skill to discriminate L2 vowels [@mokari2018perceptual], and musical knowledge contributes to L2 tone discrimination [@ngo2016effects].
However, musical knowledge does not contribute to the creation of L2 tone-segment connections when the L1 does not encode tones; only a tonal L1 promotes the creation of L2 tone-segment connections and of a rule-like system of L2 tone information [@chan2019lexical]. 
Likewise, musical ability in general is not associated with the ability to discriminate and produce L2 sounds [@mokari2018perceptual].

From this set of results, we can deduce that there is a limit in the reciprocal influence between music and language (musical and linguistic pitch for the purpose of this project), but where this limit lies has not been ascertained. 
The research on the relationship of speech sounds with music has been mostly conducted with tones and about discrimination.
Exploring other structures in speech that conform the prosody of a language, namely lexical stress and moras, could provide insight into the connection between pitch and speech.

_Rhythm_    
Rhythm is defined as a pattern of recurrent time intervals that usually occur periodically [@berlyne1971aesthetics].
This periodic nature allows to predict the start of an interval or the next recurring event based on what has already been perceived [@fraisse2013rhythm; @martin1972rhythmic]. 
A typical response to a rhythm is synchronized movement to it. 
This sensorimotor behavior is based on anticipation of when the next beat is coming, especially at slow tempi [@nozaradan2016individual; @van2015sensorimotor].
Ability to perform this anticipation grows in accuracy with years of musical training [@nozaradan2016individual]. 
Prediction of oncoming beats is also present in rhythms with tempo changes [@van2015sensorimotor].   
Within the auditory modality, music is probably the most obvious instance of rhythm, but other domains such as language also follow rhythmic patterns.
Metrical expectancies are automatically generated as we listen to speech [e.g., @magne2016speech; @rothermich2012rhythm; @schmidt2009event]. 
Speakers use stress patterns to generate the expectancies. 
The expectancies are created because the stress patterns are connected to other linguistic levels. 
For instance, stress can be associated with word endings [@soto2001], such that by hearing a specific stress patterns, the speaker can predict verb tense [@sagarra2018; @primerexperimento].
Speakers need to learn these associations.
External factors such as learning context [@primerexperimento] or verb frequency may contribute to the easiness with which the connections is created. 
However, internal factors may also contribute. 

Individual differences in music rhythm abilities can account for speech rhythm sensitivity [@magne2016].
The similarity of rhythmic processing in music and speech may involve shared cognitive mechanisms to perceive and process the rhythms in different domains that may be causing the individual differences.
If the mechanisms are shared, then increased abilities in rhythm, be them innate or acquired through practice, may have an effect on discrimination and processing of rhythms in language.
Indeed, rhythmic abilities and perception condition L1 and L2 processing. 
Matching metrical primes facilitate processing of sentences in the L1 [@cason2015bridging].
ERP recordings have shown that on-beat sequence primes result in faster L1 speech processing than off-beat primes in adults [@cason2012rhythmic]. Rhythmic production is positively associated with L2 lexical stress placement and rhythm perception with the L2 learning experience [@bhatara2015foreign; @cason2019rhythmic].
Better increased rhythmic perception, in contrast, is not associated with adults' reading abilities in an L1 or L2 [@swaminathan2018explaining].
Swaminathan and colleagues were, nevertheless, mixing modalities (written text and heard rhythms), while Cason and colleagues were not. 
We could therefore hypothesize that a relationship between speech and rhythm is still not precluded.
This conclusion would also agree with with association learning models proposing that the more similar two cognitive specific domains are, the likelier the transfer of abilities and mechanisms between them is.

In order to extend the current findings on the association between music and speech to predictive processing, we tested transfer of pitch, rhythm and speech anticipation abilities of monolingual and L2 speakers of Spanish at intermediate and advanced levels of proficiency.
The L2 speakers' L1s shared with Spanish rhythmic structure (Chinese-Spanish bilinguals) or pitch use for lexical stress (English-Spanish bilinguals).

## 2.3. Transfer
Transfer refers to the use and application of skills or knowledge acquired in a cognitive domain to an activity in a different domain, or the inability to do so [@singley1989transfer].  
Transfer models focus on transfer of domain-general or domain-specific mechanisms to other specific domains.
In the first case, if inhibitory control were transferred to driving, that would be an example of transfer of a domain-general cognitive mechanism to a specific domain.
In types of models accounting for this type of transfer, different brain domains are connected to each other allowing for transfer of acquired skills in a domain towards another not as specialized skill in a different domain.
This transfer is enabled through the sharing of common features [@thorndike1901influence] and cognitive elements [@anderson1990cognitive], in the form of perceptual and conceptual information [@singley1989transfer].

If visuospatial skills to gauge trajectories or distance were transferred from playing a sport to driving, that would be an example of transfer of a domain-specific cognitive mechanism to a specific domain.
In models accounting for this type of transfer, brain domains are independent and unrelated to each other.
The independency will stem from the idea that the more developed a skill is, the more domain-specific the features will be, reducing the likelihood of transfer as they cannot apply as easily to skills in other domains [@ericsson1994expert; @gobet2015understanding].
Improvement of skills in a brain domain will consequently have little to no influence in other domains.

The influence of domain-general mechanisms on language prediction has been started to be explored with verbal working memory [@huettig2016prediction; @otten2019does; @sagarra@2018], although no agreement on the influence has been reached so far and more extensive research is still needed to that end.
So far, verbal working memory has shown to have little to no effect, even in non-proficient L2 speakers who are more prone to performance differences caused by working memory _[@citation]_.
Regarding the influence of other domain-specific mechanisms, this is to our knowledge the first study exploring the influence of domain-specific mechanisms pertaining to other specific domains (i.e., rhythm and pitch).

## 2.4. Linguistic phenomena
### 2.4.1. Pitch
Pitch can be associated with a number of phonological and intonational phenomena in speech.
Interestingly for the present study, pitch can be associated with the emphasis that some syllables receive in comparison to others not as emphasized.
This association gives place to lexical stress [@hualde2005sounds].
In the lexical stress association, the emphasized or stressed syllable has a higher pitch, while the unstressed syllable has a lower pitch.
Lexical stress is present in languages like English and Spanish.
In these languages, the differences in pitch between stressed and unstressed syllables in Spanish and English distinguishes words.
That is, lexical stress, the difference in pitch height, is contrastive.
In English, lexical stress predominantly distinguishes heteronyms or pairs of verbs-nouns that have no segmental differences, such as to “proDUCE,” verb vs “PROduce,” noun. 
In Spanish, lexical stress differentiates all kinds of information, such as verbal tense and person (*CANto* 'I sing' vs _canTÓ_ 's/he sang'), nouns (*PApa* 'potato' vs _paPÁ_ 'dad'), or nouns from verbs (*TÉRmino* 'term' vs _terMIno_ 'I finish' vs _termiNÓ_ 's/he finished').
Lexical stress is however also marked by other acoustic correlates in combination with pitch.
Such acoustic correlates are duration and vowel quality in English [@cooper2002constraints; @cutler1986forbear] or intensity in Spanish [@hualde2005sounds; @ortega2006phonetic; @ortega2007disentangling; @ortega2009perception].

In addition to lexical stress, pitch can be associated with other phonological phenomena at the lexical level.
In languages like (or dialects belonging to) Mandarin Chinese, pitch is associated with tones [@gandour1978perception; @zhu2015tone].
In Mandarin tones, it is not pitch height relativity what is important, but pitch contour [@chao1968grammar].
In other words, whether pitch remains at a specific height, it goes up or down within a syllable.
Another remarkable difference between tones and lexical stress is that all syllables of a word in a tonal language are associated to a tone.
In contrast, only one syllable in each word may be stressed, although the presence of secondary stress is also possible in English.
Some words may also not be stressed at all.
Like lexical stress in Spanish and English, tones in Mandarin Chinese contribute to word distinction [/ma1/mā/ 'mother', /ma2/má/ 'hemp', /ma3/mǎ/ 'horse', /ma4/mà/ 'scold'].

### 2.4.2. Rhythm
The phonological structure associated with syllables determines the overall rhythmic effects of the language.
Vowel reduction in English causes unstressed syllables to be considerably shorter than stressed syllables.
The shortening of syllables causes the stressed syllable to signal the start of a new rhythmic unit.
These rhythmic units are thus composed of the stressed syllable plus the following unstressed syllables until the following stressed syllable arrives.
Languages with this rhythmic structure may be described as stressed-time.

In languages like Spanish that have no vowel reduction, all syllables last approximately the same regardless of their tonicity [@colantoni2015second; @hualde2005sounds]. 
In these languages, stress is simply part of a syllable, and each syllable is a new rhythmic unit. 
These languages may be described as syllable-timed.
Since pitch is the only correlate to tones in Mandarin Chinese, syllables have all similar duration.
Therefore, Mandarin is also described as a syllable-timed language in terms of rhythm [@grabe2002durational; @lin2007mandarin; @mok2009syllable].
     
# 3. This study
Previous research has mainly explored external factors that condition the ability of L2 speakers' to create associations for predictive processing.
In those studies, individual differences as a source of variability was rarely consider.
In the studies in which individual variability was considered, the factor included was verbal working memory.
Verbal working memory has not been proven to be effective in accounting for individual variability so far _[@]_, although the studies on the topic are not that numerous.
With the goal of expanding the possibilities giving rise to individual variability, here we focused on individual variability that may stem from innate skills specific to other cognitive domains.
The skills are namely auditory skills.
Linguistic skills have been oftentimes previously associated with musical skills in pitch perception and rhythm production.
Most of these studies, however, have been conducted on professional musicians, which may have masked individual variability caused by the innate pitch and rhythm processing abilities of the speakers.
Here, therefore, we expanded previous findings by testing the relationship of predictive abilities between specific cognitive domains that were linguistic (phonology) and non-linguistic (pitch and rhythm) to explore the possibility that individual differences in language processing can be caused by innate auditory abilities.
To that end, monolingual speakers of Spanish and English and Chinese learners of Spanish at different levels of proficiency completed an eye-tracking task, a pitch anticipatory task, and a rhythm synchronization task.
The eye-tracking task measured speakers' abilities to predict verb tense suffixes through lexical stress.
The pitch anticipatory task measured speakers' abilities to predict upcoming tones in a melody based on the previously heard tones.
The rhythm synchronization task measured speakers' abilities to predict beats and synchronize key presses to them.

The research question guiding the study was



As described above, English and Spanish share the use of pitch height to indicate lexical stress and apply lexical stress to contrast words.
English and Spanish, however, differ in their rhythmic structure due to the different duration of English syllables depending on tonicity.
Mandarin Chinese dialects and Spanish share the rhythmic structure as they are both syllable timed, but they differ in their use of pitch (tones in Mandarin and stress in Spanish) and the particular aspect of pitch they pay attention to (contour vs height, respectively).
Although some scholars have proposed that Mandarin Chinese also encodes lexical stress, 


We therefore predict that 


